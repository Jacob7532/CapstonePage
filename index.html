<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ASR Attack Capstone</title>
    <style>
        body {
            background-color: #121212;
            color: #ffffff;
            font-family: 'Arial', sans-serif;
            margin: 0;
            line-height: 1.6;
        }

        header {
            background-color: #1e88e5;
            padding: 20px;
            text-align: center;
        }

        h1 {
            margin: 0;
            color: #ffffff;
            font-size: 2em;
        }

        h3 {
            margin-top: 5px;
            color: #ffffff;
            font-size: 1.2em;
        }

        .members {
            background-color: #263238;
            padding: 20px;
            border-radius: 10px;
            margin-top: 20px;
        }

        .members h2 {
            color: #ffffff;
            font-size: 1.5em;
            margin-bottom: 10px;
        }

        .members p {
            color: #ffffff;
            margin-bottom: 15px;
        }

        .members ul {
            list-style-type: none;
            padding: 0;
        }

        .members li {
            margin-bottom: 8px;
        }

        .paragraph {
            background-color: #37474f;
            padding: 20px;
            border-radius: 10px;
            margin-top: 20px;
        }

        .paragraph h2 {
            color: #ffffff;
            font-size: 1.5em;
            margin-bottom: 10px;
        }

        .paragraph p {
            margin-bottom: 0;
        }

        .resources {
            background-color: #455a64;
            padding: 20px;
            border-radius: 10px;
            margin-top: 20px;
        }

        .resources h2 {
            color: #ffffff;
            font-size: 1.5em;
            margin-bottom: 10px;
        }

        .resources ul {
            list-style-type: none;
            padding: 0;
        }

        .resources li {
            margin-bottom: 8px;
        }

        .resources a {
            color: #bbdefb;
            text-decoration: none;
        }

        .resources a:hover {
            text-decoration: underline;
        }
        .assignments {
          background-color: #818589;
          padding: 20px;
          border-radius: 10px;
          margin-top: 20px;
        }
  
        .assignments h2 {
            color: #ffffff;
            font-size: 1.5em;
            margin-bottom: 10px;
        }
  
        .assignments ul {
            list-style-type: none;
            padding: 0;
        }
  
        .assignments li {
            margin-bottom: 8px;
        }
  
        .assignments a {
            color: #bbdefb;
            text-decoration: none;
        }
  
        .assignments a:hover {
            text-decoration: underline;
        }
        .methods {
          background-color: #53565a;
          padding: 20px;
          border-radius: 10px;
          margin-top: 20px;
        }

        .methods h2 {
            color: #ffffff;
            font-size: 1.5em;
            margin-bottom: 10px;
        }

        .methods ul {
            list-style-type: none;
            padding: 0;
        }

        .methods li {
            margin-bottom: 8px;
        }

        .methods a {
            color: #bbdefb;
            text-decoration: none;
        }

        .methods a:hover {
            text-decoration: underline;
        }
        .center {
            display: block;
            margin-left: auto;
            margin-right: auto;
            width: 50%;
        }
        
    </style>
</head>

<body>
    <header>
        <h1>ASR Attack</h1>
        <h3>Group 4</h3>
    </header>

    <section class="members">
        <center>
        <h2>Class</h2>
        <p>CS 426 Senior Project in Computer Science, Spring 2024, at UNR, CSE Department</p>

        <h2>Professors</h2>
        <ul>
            <li>David Feil-Seifer</li>
            <li>Devrin Lee</li>
            <li>Sara Davis</li>
        </ul>

        <h2>Advisors</h2>
        <ul>
            <li>Dr. Rui Hu - Assistant Professor in the Department of Computer Science & Engineering at the University of Nevada, Reno</li>
            <li>Chase Carthen - Research Data Architect</li>
            <li>Zikai Zhang - UNR CSE Graduate Student</li>
        </ul>

        <h2>Group Members</h2>
        <ul>
            <li>Kristian Konstantinov</li>
            <li>Zachary Strazi</li>
            <li>Cody Long</li>
            <li>Jacob Ayers</li>
        </center>
        </ul>
    </section>

    <section class="paragraph">
        <center>
        <h2>About Our Project</h2>
       
        <p>Technology has advanced vastly over the past 20 years to the point where many devices take advantage of smart voice technology, from phones to physical devices that sit in your home and provide help with different tasks. Many devices today rely on Automatic Speech Recognition (ASR) to identify keywords and phrases that trigger their functionality. Our project aim is to create Adversarial Examples (AE) that can be created by using methods of perturbing audio and then concurrently playing them while an auditory command that is given to ASR devices and cause them to misclassify the given command. First we attacked the Wav2Vec2 model, as well as the Whisper model to determine how efficient the AE’s are at causing a misclassification. We then tested our AE’s on APIs like Google, Amazon and DeepSpeech to cause a misclassification in a given command. To deliver the attacks, we used a Raspberry Pi device to listen for the trigger phrase and play the AE at the same time a user gives a command. The ASR device will then receive the user input as well as the AE simultaneously and misclassify the command.</p>
        <img src="Screenshot 2024-03-07 181056.png" width="600" height="300" alt="Example Image" class="center">
        <h4>Raspberry PI Demo</h4>    
        <video width="800" controls autoplay>
        <source src="Untitled video (5).mp4" type="video/mp4">
        </video>
        <h4>ASR Misclassification</h4>
        <video width="800" controls autoplay>
        <source src="IMG_2077 (1).mov" type="video/mp4">
        </center>
    </section>

    <section class="resources">
        <center>
        <h2>Problem Domain Book</h2>
        <ul>
            <li>LI, J., Deng, L., Haeb-Umbach, R., & Gong, Y. (2015). Robust Automatic Speech Recognition: A Bridge to Practical Applications (1st ed.). Academic Press.
            </li>
        </ul>
        <h2>Related Resources</h2>
        <ul>
            <li>Abdullah, H., Rahman, M. S., Garcia, W., Warren, K., Yadav, A. S., Shrimpton, T., & Traynor, P. (2021). Hear “no evil”, see “kenansville”:</br> Efficient and transferable black-box attacks on speech recognition and Voice Identification Systems. 2021 IEEE Symposium on Security and Privacy (SP). <a href="https://doi.org/10.1109/sp40001.2021.00009" target="_blank">IEEE</a></li>
            </br>
            <li>Carlini N, Wagner D. Audio Adversarial Examples:</br> Targeted Attacks on Speech-to-Text. IEEE Xplore. <a href="doi:https://doi.org/10.1109/SPW.2018.00009" target="_blank">IEEE</a></li>
            </br>
            <li>Y. Chen, X. Yuan, J. Zhang, Y. Zhao, S. Zhang, K. Chen, and X. Wang, “Devil’s whisper:</br> A general approach for physical adversarial attacks against commercial black-box speech recognition devices,” in 29th USENIX Security Symposium (USENIX Security 20), 2020.</li>
            </br>
        </ul>
        <h2>Related Links</h2>
        <ul>
            <p><a href="https://github.com/kwarren9413/kenansville_attack/blob/master/README.md">KenansVille Attack</a></p>
            <p><a href="https://github.com/RiskySignal/Devil-Whisper-Attack">Devils Whisper</a></p>
            <p><a href="https://nicholas.carlini.com/">Nicholas Carlini</a></p>
        </center>
        </ul>
    </section>
    <section class="assignments">
        <center>
        <h2>Project Assignments</h2>
        <ul>
            <p><a href="https://docs.google.com/document/d/1W6CCi4A_agyxoqVzdUJNncBaryD-oAeowiCVHtbwH9g/edit?usp=sharing">Project Proposal Cs 425</a></p>
            <p><a href="https://docs.google.com/document/d/1ZcyU_OnE4O3uGQ_w1bZLcNY6LYg9MAKM5D_hJo_TdPo/edit?usp=sharing">Part 2 Specification Cs 425</a></p>
            <p><a href="https://docs.google.com/document/d/1TF67I76xl00qo2x3vptkTtozCFejuSVaib4sFk2UWgE/edit?usp=sharing">Part 3 Design Cs 425</a></p>
            <p><a href="https://docs.google.com/document/d/11VJXepqo2p-x-trvIDyBMwu5-e-OyQBp9cB_MtJDbRE/edit?usp=sharing">Part 4 Prototype Cs 425</a></p>
            <p><a href="https://docs.google.com/document/d/1K4gMTEk_Eo6HGyp4cBo4v1dEyxKpGkn65LhU0cxB_BI/edit?usp=sharing">Part 1 Revised Project Proposal Cs 426</a></p>
            <p><a href="https://docs.google.com/document/d/1KJ5oG_SRqBglU2YDUMG3C2nLQ2lrvAz8b2hABUdh9O8/edit?usp=sharing">Part 2 Revised Spec and Design Cs 426</a></p>
            <p><a href="https://docs.google.com/document/d/18ucTqCq3Kz_oeOWO7RPa5KTug_7lAcLYTi-8xzEi8Hk/edit?usp=sharing">Part 3 Acceptance Criteria and Testing Plan Cs 426</a></p>
            <p><a href="https://docs.google.com/document/d/1hfUZDyuW_Y0cR3KxJ2C0SOCGZYbtwxaO6NQaqbBujoA/edit?usp=sharing">Part 4 Project Progress Demo Cs 426</a></p>
        </center>
        </ul>
    </section>
    <section class="methods">
        <center>
        <h2>Attack Methods</h2>
        <ul>
        <h3>FFT (Fast Fourier Transformation)</h3>
        <p>FFT in an algorithm that calculates the DFT (Discrete Fourier Transformation) of a series. Any signal can be represented by a series of sine functions that add up to the original signal. The DFT is used to extract frequency information about audio in any ASR (Automatic Speech Recognition) System. Allows a vector of attack where certain frequency ranges can be downplayed that would be less perceivable to people while causing misclassifications for ASR systems.</p>
        <h4> Spectrogram of original audio vs FFT audio</h2>
        <img src="Screenshot (452).png" width="400" height="200" alt="Example Image">
        <p><a href="https://drive.google.com/file/d/1squCHy2swBzdj261gpoopIZROvo1psdO/view?usp=sharing">FFT Audio EX. 1</a></p>
        <p><a href="https://drive.google.com/file/d/1AHfWx0qrpdhW3ara8ILZeB1bWFx9clSB/view?usp=sharing">FFT Audio EX. 2</a></p>
        <h3>SSA (Singular Spectrum Analysis)</h3>
        <p>Deconstructs a time series into a few smaller subsets of components that represent various trends and noise that can be summed back into the original data or certain subsets can be isolated or removed from the time series including the noise. Lowering the intensity of frequencies less perceptible to the human ear can allow for misclassifications by ASR systems while the overall audio is still perceivable to people.</p>
        <h4> Spectrogram of original audio vs DCT audio</h2>
        <img src="Screenshot (455).png" width="400" height="200" alt="Example Image">
        <p><a href="https://drive.google.com/file/d/17TJBKk4Lxn8rpm2vH5pHV5BTABD8eCoP/view?usp=sharing">SSA Audio EX. 1</a></p>
        <p><a href="https://drive.google.com/file/d/1FkUrJ8YG8FJ-78cZW3F5QGr1Bn62K8V9/view?usp=sharing">SSA Audio EX. 2</a></p>
        <h3>DCT (Discrete Cosign Transformation)</h3>
        <p>Algorithm for compression where low energy parts can be discarded. Maintaining the coefficients that sum to the most significant part of the signal's energy. Maintaining these parts makes the original audio still perceivable, while more noisy, but requires less overall information. In our case the intensity of these low energy parts can be manipulated in order to generate a misclassification in ASR system while being perceivable to people.</p>
        <h4> Spectrogram of original audio vs SSA audio</h2>
        <img src="Screenshot (454).png" width="400" height="200" alt="Example Image">
        <p><a href="https://drive.google.com/file/d/1cu53Ui-WmssK8n3kuWrqdFF0aUEBGNew/view?usp=sharing">DCT Audio EX. 1</a></p>
        <p><a href="https://drive.google.com/file/d/1Jmtvv-CYQYZTSnqTBT-QYZ7Io9M_IvHQ/view?usp=sharing">DCT Audio EX. 2</a></p>
        <h3>Overlay</h3>
        <p>Method of attack consisting of combining two different sources of audio on top of each other in order to produce a misclassification by ASR systems.</p>
        <h4> Spectrogram of original audio vs Overlay audio</h2>
        <img src="Screenshot (447).png" width="400" height="200" alt="Example Image">
        <p><a href="https://drive.google.com/file/d/1squCHy2swBzdj261gpoopIZROvo1psdO/view?usp=sharing">Overlay Audio EX. 1</a></p>
        <p><a href="https://drive.google.com/file/d/11AMOIVPl1vutrBbN6hFlx7XeEbbW2pTT/view?usp=sharing">Overlay Audio EX. 2</a></p>
        </center>
        </ul>
    </section>
</body>

</html>
